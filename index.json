[{"categories":["MIT 18.x"],"contents":"Unit 1: The Intergral Preface This is the note of the MIT Course 18.01.1 Calculus. For more details, refer to MIT 18.x Catalog, and it can also be found at MIT Open Learning Library.\nMean Value Theorem The Mean Value Theorem (MVT) If $x(t)$ is continuous on $a\\le t\\le b$, and differentiable on $a\u0026lt;t\u0026lt;b$, that is, $x^{\\prime}(t)$ is defined for all $t$, $a\u0026lt;t\u0026lt;b$, then $$ \\frac{x(b)-x(a)}{b-a}=x^{\\prime}(c)\\qquad \\text{for some }c\\text{, with }a\u0026lt;c\u0026lt;b $$ Equivalently, in geometric terms, there is at least one point $c$, with $a\u0026lt;c\u0026lt;b$, at which the tangent line is parallel to the secant line through $(a,x(a))$ and $(b,x(b))$:\nUpper and Lower Bounds We have introduced the notion of upper and lower bounds.\nA number $M$ is an uppper bound of a function $f(x)$ if $$ f(x)\\le M\\quad \\text{for all }x $$ and a number $m$ is a lower bound of a function $f(x)$ if $$ m\\le f(x)\\quad \\text{for all }x $$ We can consider upper and lower bounds on the entire real number line, or on an interval.\n$$\rm\\le f(x)\\le M\r$$\rIn other words, an upper bound of a function is a number that is larger than or euqual to all values of the function. A lower bound of a function is a number which is smaller than or equal to all values of the function.\rOld News We have been relying on the following fundamental facts whenever we try to understand a function using its derivative. But in fact, these facts are consequences of the MVT.\nIf $x^{\\prime}(t)\\ge 0$ for all $t$ in $(A,B)$, then $x(t)$ is increasing or staying the same over $[A,B]$. If $x^{\\prime}(t)\u0026gt;0$ for all $t$ in $(A,B)$, then $x(t)$ is strictly increasing over $[A,B]$. If $x^{\\prime}(t)\\le 0$ for all $t$ in $(A,B)$, then $x(t)$ is decreasing or staying the same over $[A,B]$. If $x^{\\prime}(t)\u0026lt; 0$ for all $t$ in $(A,B)$, then $x(t)$ is strictly increasing over $[A,B]$. IF $x^{\\prime}(t)=0$ for all $t$ in $(A,B)$, the $x(t)$ is constant over $[A,B]$. These facts need proofs and their proofs are based on the MVT. The subtlety is that the MVT relates the infinitesimal behviour of the function, the derivative, which is defined at a point, to the macroscopic behviour of the function, the total change over an interval.\nBounding The Average Rate of Change The equality in the MVT can be used to restrict the range of possible values of the average rate of change and the total change.\nMore precisely, if there are numbers $m$ and $M$ such that $$ m\\le x^{\\prime}(c)\\le M\\qquad\\text{for all }c\\text{ with }a\u0026lt;c\u0026lt;b $$ that is, $m$ is a lower bound and $M$ is an upper bound on $x^{\\prime}(c)$ over $(a,b)$, then the MVT implies the following: $$ \\begin{aligned} m\\ \\ \u0026amp;\\le\\ \\frac{x(b)-x(a)}{b-a}\\ \\le\\ M\\qquad \\text{(Bounds on the average rate of change)}\\\\ m\\cdot (b-a)\\ \u0026amp;\\le\\ x(b)-x(a)\\ \\le\\ M\\cdot (b-a)\\qquad \\text{(Bounds on the total change)} \\end{aligned} $$\nIn other words, a lower bound on the derivative is also a lower bound on the average rate of change, and an upper bound on the derivative is also an upper bound on the average rate of change. Also, the product of a lower bound on the derivative with the length of an interval, is a lower bound on the total change of the function over that interval. Similarly, the product of an upper bound on the derivative with the length of an interval, is an upper bound on the total change of the function over that interval.\nWhen we know the maximum and minimum values of $x^{\\prime}(t)$, we can use them as bounds on $x^{\\prime}(t)$ and obtain the following. $$ \\begin{alignat*}{2} \\min_{a\\le t\\le b}x^{\\prime}(t) \u0026amp;\\le \\frac{x(b)-x(a)}{b-a} \u0026amp;\u0026amp;\\le \\max_{a\\le t\\le b}x^{\\prime}(t) \\quad\\text{(Bounds on the average rate of change)} \\\\ \\min_{a\\le t\\le b}x^{\\prime}(t)\\cdot (b-a) \u0026amp;\\le x(b)-x(a) \u0026amp;\u0026amp;\\le \\max_{a\\le t\\le b}x^{\\prime}(t)\\cdot (b-a) \\quad\\text{(Bounds on the total change)} \\end{alignat*} $$ In other words, the average rate of change must be in between the maximum and the minimum of the derivative, and the total change must be in between the maximum and minimum of the derivative multiplied by the length of the interval.\nDifferentials \u0026amp; Antiderivatives Differential Notation Let $y=F(x)$, the differential of y is defined as $$ dy=f^{\\prime}(x)\\cdot dx $$ This is also called the differrential of F and denoted dF.\nRearranging this equation, we get the Leibniz notation for the derivative, which says the derivative is the ratio of the two differentials $dy$ and $dx$. $$ F^{\\prime}(x)=\\frac{dy}{dx}\\qquad \\left(\\text{or}\\ \\frac{dF}{dx}\\right) $$ We may think of the differential of $x$, $dx$, as a \u0026ldquo;little bit\u0026rdquo; of $x$, and the differential of $y$, $dy$, as a \u0026ldquo;little bit\u0026rdquo; of $y$. Here what we mean by a \u0026ldquo;little bit\u0026rdquo; is really an infinitely small bit, we call these infinitely small quantities \u0026ldquo;infinitesimals\u0026rdquo;. The point is that even though both $dy$ and $dx$ are infinitely small, their ration is NOT. Their ratio is the derivative $F^{\\prime}(x)$. In other words, the differential notation says that $dy$ is proportional to $dx$ with constant of proportionaliyu $F^{\\prime}(x)$ even though both $dy$ and $dx$ are infinitely small. We use the differential notation as a tool to keep track of how much $y$ changes when $x$ changes by a tiny tiny \u0026hellip; tiny bit.\nThe geometric picture for the differential is the same as that for linear approximation.\nLet us compare the differential notation with the formula for linear approximations.\n$$ \\begin{alignat*}{2} \\text{Linear Approximation at }x\\quad \\Delta F\\quad \u0026amp;\\approx\\quad F^{\\prime}(x)\\cdot \\Delta x,\\quad \u0026amp;\u0026amp;\\Delta x\\text{ is a finite change in }x\\\\ \\text{Differential Notation}\\quad dF\\quad \u0026amp;=\\quad F^{\\prime}(x)\\cdot dx,\\quad \u0026amp;\u0026amp; dx\\text{ is a tiny tiny \u0026hellip; tiny bit of }x \\end{alignat*} $$\nAntiderivatives An antiderivative of $f(x)$ is any function $F(X)$ such that $$ F^{\\prime}(x)=f(x) $$\nIndefinite Integral Given a function $f(x)$, the indefinite integral or the antiderivative of $f(x)$ is denoted $\\displaystyle\\int f(x) \\ dx$. It is the family of functions $$ \\int f(x)\\ dx\\ =\\ F(x)+C $$ where $F(X)$ is any antiderivative of $f(x)$, and $C$ is any constant.\nWe call $\\int$ the integral sign, $f(x)$ the integral, and $C$ the constant of integration.\nThe constant of integration is present in this definition because the derivative of a function determines only the shape of the function, but the derivative does not change if the function is shifted up or down by the same constant everywhere.\nUniqueness of the Indefinite Integral The indefinite integral $$ \\int f(x)\\ dx\\ =\\ F(x)+C $$ is termed \u0026ldquo;indefinite\u0026rdquo; since it contains an undetermined constant $C$ and is not just one function but a family of infinitely many functions, parameterized by $C$.\nOn the other hand, the constant is the only ambiguity of the indefinite integral due to the MVT, which guarantees that any two antiderivatives of the same function can differ only by a constant.\nIntegrals of Powers $$ \\int x^P\\ dx\\ =\\quad \\begin{cases} \\dfrac{x^{P+1}}{p+1}, \u0026amp; \\text {if $p\\ne -1$} \\\\ \\ln{(\\vert x\\vert)}, \u0026amp;\\text{if $p=-1$} \\end{cases} $$\nFirst Rules of Integration $$ \\begin{array}{lcc} \u0026amp; \\text{Integration Rules} \u0026amp; \\text{Differentiation Rules} \\\\ \\text{Constant Multiple: } \u0026amp; \\displaystyle\\int k f(x)\\ dx=k\\int f(x)\\ dx \u0026amp; d(k F)=k\\ dF \\\\ \\text{Sum: } \u0026amp; \\displaystyle\\int{(f(x)+g(x))\\ dx}=\\int{f(x)\\ dx}+\\int{g(x)\\ dx} \u0026amp; d(F+G)=dF+dG \\end{array} $$ On the other hand, the following naive product and quotient rules do NOT work.\n$$ \\int f\\cdot g\\ dx\\quad\\textbf{DOES NOT EQUAL}\\quad(\\int f\\ dx)\\cdot(\\int g\\ dx)\\\\ \\int \\frac f g\\ dx\\quad\\textbf{DOES NOT EQUAL}\\quad\\frac{\\int f\\ dx}{\\int g\\ dx} $$\nMethod of Substituion The method of substitution is the integration analogue of the chain rule.\nIf $$ g(x)\\ dx\\quad =\\quad f(u(x))u^{\\prime}(x)\\ dx $$ that is, the differential $g(x)\\ dx$ is the result of a chain rule, then $$ \\begin{aligned} \\int g(x)\\ dx\\quad =\u0026amp;\\quad\\int f(u(x))u^{\\prime}(x)\\ dx\\\\ =\u0026amp;\\quad\\int f(u)\\ du\\\\ =\u0026amp;\\quad F(u(x))+C \\end{aligned} $$ where $F(u)$ is an antiderivative of $f(u)$.\n","date":"2025-03-15T00:00:00Z","permalink":"https://jiansyuan.github.io/post/mit_18.01/mit_18.01.2_calculus_ib-unit1/","section":"post","tags":["Note","Mathematics","Calculus"],"title":"Notes on MIT 18.01.2 Calculus IB (Unit1 Integral)"},{"categories":["MIT 18.x"],"contents":"Preface This is the note of the MIT Course 18.01.1 Calculus. For more details, refer to MIT 18.x Catalog, and it can also be found at MIT Open Learning Library.\nUnit 4: Application Definition of Critical Points The critical points of a function $f(x)$ to be all points $x$ in the domain of $f(x)$ such that\n$f^\\prime(x)=0$, or $f^\\prime(x)$ does not exist. The First Derivative Test Finding Local Maxima and Minima Suppose the function $f(x)$ is continuous at $x=a$ and has a critical point at $x=a$.\n$f$ has a local minimum at $x=a$ if $f^\\prime(x)\u0026lt;0$ just to the left of $a$ and $f^\\prime(x)\u0026gt;0$ just to the right of $a$.\n$f$ has a local maximum at $x=a$ if $f^\\prime(x)\u0026gt;0$ just to the left of $a$ and $f^\\prime(x)\u0026lt;0$ just to the right of $a$.\nThe point $x=a$ is neither a local minimum nor a local maximum of $f$ if $f^\\prime(x)$ has the same sign just to the left of $a$ and just to the right of $a$.\nThe Second Derivative Test Suppose that $x=a$ is a critical point of $f$, with $f^\\prime(a)=0$.\nIf $f^{\\prime\\prime}(a)\u0026gt;0$, then $f$ has a local minimum at $x=a$.\nIf $f^{\\prime\\prime}(a)\u0026lt;0$, the $f$ has a local maximum at $x=a$.\nIf $f^{\\prime\\prime}(a)=0$, or does not exist, then the test is inconclusive, which means there might be a local minimum, or a local maximum, or neither.\nDefinition of Inflection Point An inflection point is a point where the concavity of the function changes. That is the second derivative $f^{\\prime\\prime}(x)$ changes sign:\n$f^{\\prime\\prime}\u0026gt;0$ just to the left of $x$ and $f^{\\prime\\prime}(x)\u0026lt;0$ just to the right of $x$, or vice versa.\nGeneral Strategy for Sketching Functions Plot discontinuities (especially infinite ones) end points (or $x\\to \\infty$) easy points ($x=0, \\text{ or }y=0$) Plot critical points and values. (Solve $f^{\\prime}(x)=0$ or undefined.) Decide whether $f^{\\prime}\u0026lt;0$ or $f^{\\prime}\u0026gt;0$ on each interval between endpoints, critical points, and discontinuities. (Valuable double check) Identify where $f^{\\prime\\prime}\u0026lt;0$ and $f^{\\prime\\prime}\u0026gt;0$ (concave down and concave up). Identify inflection points. Combine into graph. Indeterminate Forms We call $\\frac 0 0$ and $\\frac {\\infty}{\\infty}$ indeterminate forms, because when we run into them in a limit, they require further analysis to determine whether the numerator or denominator wins in the race to $0$ or $\\infty$ respectively, or whether they balance out and reach some other finite limit.\nL'Hôspital's Rule If $$ \\left. \\begin{aligned} \u0026amp;f(x)\\to 0 \\\\ \u0026amp;g(x)\\to 0 \\end{aligned} \\right. \\quad as\\ x\\to a $$ and the functions $f$ and $g$ are differentiate near the point $x=a$, then limit $$ \\lim_{x\\to a}\\frac{f(x)}{g(x)}=\\lim_{x\\to a}\\frac{f^{\\prime}(x)}{g^{\\prime}(x)} $$ provided that the left hand limit and the right hand limit exists or is $\\pm\\infty$. Note that\nWe can replace $a$ with $a^+$ or $a^-$ and the results still hold. We can replace $a$ with $\\pm\\infty$, and the results still hold. Other Indeterminate Forms Other indeterminate forms $0\\cdot\\infty$, $\\infty -\\infty$, $0^0$, $1^\\infty$ and $\\infty^0$ should be rearranged to be of the form $0/0$ or $\\infty / \\infty$ in order to apply L\u0026rsquo;Hôpital\u0026rsquo;s rule.\nThe Extreme Value Theorem If $f$ is continuous on a closed interval $[a,b]$, then there are points at which $f$ attains its maximum and its minimum on $[a,b]$.\nMaxima and Minima The maxima and minima will be attained at either a critical point or an end point.\n","date":"2025-03-07T00:00:00Z","permalink":"https://jiansyuan.github.io/post/mit_18.01/mit_18.01.1_calculus_ia-unit4/","section":"post","tags":["Note","Mathematics","Calculus"],"title":"Notes on MIT 18.01.1 Calculus IA (Unit4 Application)"},{"categories":null,"contents":"This blog website was originally created several years ago when I was in high school. Initially, it hosted a collection of articles I casually wrote about algorithm competitions. However, I later discovered that the website had poor support for LaTeX, with some formula subscripts misaligned in Chrome. Due to time constraints, I never got around to fixing it. Now, on March 6, 2025, after a thorough reorganization, the website stands in its current form.\nThe texts below is from the initial version of this website.\nHowdy! Welcome to my blog website! Some diurnal, practise, ruminate \u0026amp; comprehend of myself will be put here. See at Articles.\nMe A student who is interested in algorithms and mathematics. You can find me through these links below.\nMail: JiansYuan@outlook.com\nGithub: Contexploit\nZhihu: JiansYuan\n","date":"2025-03-06T00:00:00Z","permalink":"https://jiansyuan.github.io/about/","section":"","tags":null,"title":"About"},{"categories":["MIT 18.x"],"contents":"Preface This is the note of the MIT Course 18.01.1 Calculus. For more details, refer to MIT 18.x Catalog, and it can also be found at MIT Open Learning Library.\nUnit 3: Approximations Linear Approximations of Basic Functions Near 0 $$ \\begin{aligned} \u0026amp;(1+x)^r\u0026amp;\\approx\u0026amp;\\quad 1+r\\cdot x\\\\ \u0026amp;\\sin(x)\u0026amp;\\approx\u0026amp;\\quad \\sin(0)+cos(0)\\cdot x\u0026amp;=\u0026amp;x\\\\ \u0026amp;\\cos(x)\u0026amp;\\approx\u0026amp;\\quad\\cos(0)-\\sin(0)\\cdot x\u0026amp;=\u0026amp;1\\\\ \u0026amp;e^x \u0026amp;\\approx\u0026amp;\\quad e^0+e^0\\cdot x\u0026amp;=\u0026amp;1+x\\\\ \u0026amp;\\ln(1+x)\u0026amp;\\approx\u0026amp;\\quad\\ln(1+0)+\\frac 1{1+0}x\u0026amp;=\u0026amp;x \\end{aligned} $$\nBest Fit Quadratic The best fit quadratic or best fit parabola to a function $f(x)$ at the point $x=0$ is the quadratic function $q(x)$ whose value agree with the value of $f$ at $x=0$, and those first and second derivatives agree with the first and second derivatives of $f$ at $x=0$.\ni.e. $$ \\begin{aligned} f(0)\\quad \u0026amp;=\u0026amp;q(0)\\\\ f(0)^\\prime\\quad \u0026amp;=\u0026amp;q^\\prime(0)\\\\ f(0)^{\\prime\\prime}\\quad \u0026amp;=\u0026amp;q^{\\prime\\prime}(0) \\end{aligned} $$\nQuadratic Approximation The quadratic approximation near $x=a$ is the best fit parabola to $f$ at the point $x=a$.\nThe formula for the quadratic approximation of a function $f$ near a point $x=a$ is $$ f(x)\\approx f(b)+f^\\prime (a)\\cdot (x-a)+\\frac{f^{\\prime\\prime}(a)}{2}\\cdot(x-a)^2 $$ When $a=0$, this quadratic approximation becomes $$ f(x)\\approx f(0)+f^\\prime(0)\\cdot x+\\frac{f^{\\prime\\prime}(0)}2 \\cdot x^2 $$\nBig-O Notation A function $f(x)$ is on the order $x^n$ near $x=0$, which is denoted using big \u0026ldquo;O\u0026rdquo; notation as $f(x)=O(x^n)$ near $x=0$, if $\\vert f(x)\\vert \\le k\\cdot x^n$.\nNewton\u0026rsquo;s Method Given a function $f(x)$, find $x$ such that $f(x)=0$.\nMake a good guess of $x_0$.\nCall $x_1$ the $x-$intercept of the tangent line through $(x_0, f(x_0))$. It has the formula $$ x_1=x_0-\\frac{f(x_0)}{f^\\prime(x_0)} $$\nRepeat. The general formula is $$ x_{n+1}=x_n-\\frac{f(x_n)}{f^\\prime(x_n)} $$ for the $n=0,1,2,\\cdots$ .\n","date":"2025-03-05T00:00:00Z","permalink":"https://jiansyuan.github.io/post/mit_18.01/mit_18.01.1_calculus_ia-unit3/","section":"post","tags":["Note","Mathematics","Calculus"],"title":"Notes on MIT 18.01.1 Calculus IA (Unit3 Approximation)"},{"categories":["MIT 18.x"],"contents":"Preface This is the note of the MIT Course 18.01.1 Calculus. For more details, refer to MIT 18.x Catalog, and it can also be found at MIT Open Learning Library.\nUnit 2: Differentiation Linear Approximation The linear approximation for a function $f$ near a point $x=a$ is given by the following equivalent formulas: $$ \\begin{aligned} \\Delta f \u0026amp;\\approx \\left. \\frac{df}{dx}\\right |_{x=a} \\cdot \\Delta x\\quad \u0026amp;for\\ \\Delta x\\ near\\ 0\\\\ f(x)\u0026amp;\\approx f^\\prime(a)\\cdot(x-a)+f(a)\\quad \u0026amp;for\\ x\\ near\\ a \\end{aligned} $$\nThe Product Rule If $h(x)=f(x)\\cdot g(x)$, then $$ h^\\prime(x)=f(x)\\cdot g^\\prime(x)+f^\\prime(x)\\cdot g(x) $$ at all points where the derivatives $f^\\prime(x)$ and $g^\\prime(x)$ are defined.\nThe Quotient Rule If $h(x)=\\frac{f(x)}{g(x)}$ for all $x$, then $$ h^\\prime(x)=\\frac{f^\\prime(x) \\cdot g(x)-f(x)\\cdot g^\\prime(x)}{g(x)^2} $$ at all points where $f$ and $g$ are differentiable and $g(x)\\ne 0$.\nThe Chain Rule If $h(x)=f(g(x))$, then $$ h^\\prime(x)=f^\\prime(g(x))\\cdot g^\\prime(x) $$ at all points where the derivatives $f^\\prime(g(x))$ and $g^\\prime(x)$ are defined.\nAlternatively, if $y=f(u)$, and $u=g(x)$, then $$ \\left.\\frac{dy}{dx}\\right\\vert_{x=a}= \\left. \\frac{dy}{du}\\right\\vert_{u=g(a)} \\cdot \\left. \\frac{du}{dx}\\right\\vert_{x=a} $$ at any point $x=a$ where the derivatives $\\left.\\frac{dy}{du}\\right\\vert_{u=g(a)}$ and $\\left.\\frac{du}{dx}\\right\\vert_{x=a}$ are defined.\nImplicit Differentiation To implicitly differentiate a function $f(x)\\cdot g(x)=1$ with respect to $x$: $$ \\begin{aligned} \u0026amp;\\frac d {dx}(f(x)\\cdot g(y)\\quad \u0026amp;=\u0026amp; \\quad 1)\\\\ \u0026amp;\\frac d {dx}(f(x)\\cdot g(y))\\quad \u0026amp;=\u0026amp; \\quad \\frac d {dx}1\\\\ \u0026amp;\\frac d{dx}(f(x)\\cdot g(y))\\quad \u0026amp;=\u0026amp; \\quad 0\\\\ \u0026amp;f^\\prime(x)\\cdot g(x)+f(x)\\cdot\\frac{d}{dx}g(y)\\quad \u0026amp;=\u0026amp; \\quad 0\\\\ \u0026amp;f^\\prime(x)\\cdot g(x)+f(x)\\cdot g^\\prime(y)\\cdot\\frac{dy}{dx}\\quad \u0026amp;=\u0026amp; \\quad 0 \\end{aligned} $$\nDefinition of Inverser Function If functions $f$ and $g$ satisfy $g(f(x))=x$ and $f(g(y))=y$, then we say $g$ is the inverse of $f$, and denote it by $f^{-1}$. Similarly, $f=g^{-1}$.\nIf a function $f$ has an inverse function $f^{-1}$, then $f^{-1}(b)=a$ if and only if $f(a)=b$.\nDefinition of One-to-One A function $f$ is one-to-one if $f(a)\\ne f(b)$ whenever $a\\ne b$. It is one-to-one if and only if its graphy satisfies the horizontal line test(noi horizontal line intersects its graph at more than one place).\nDomain and Range Recall that the domain of a function $f$ is the set of allowable input values. For instance, the domain of the function $f(x)=\\frac 1 x$ si the set of all non-zero real numbers.\nThe range of $f$ is the set of all possible output values. For instance, the range of the function $g(x)=x^2$ is the set of all real numbers that are non-negative.\nDerivatives of Inverse Functions If $g$ is a inverse of a function $f$, then $$ g^\\prime = \\frac 1 {f^\\prime (g(x))} $$ at all $x$ where $f^\\prime(g(x))$ exists and is non-zero.\nDerivatives of the Inverse Trig Functions We now have more basic functions that we can differentiate. $$ \\begin{aligned} \\frac d {dx}\\arcsin x\\quad\u0026amp;=\u0026amp;\\quad \\frac 1 {\\sqrt{1-x^2}}\\\\ \\frac d {dx}\\arccos x\\quad\u0026amp;=\u0026amp;\\quad -\\frac 1 {\\sqrt{1-x^2}}\\\\ \\frac d {dx}\\arctan x\\quad\u0026amp;=\u0026amp;\\quad \\frac 1 {1+x^2} \\end{aligned} $$\nThe Derivative of an exponential function The derivative of the exponential function is $$ \\frac d {dx}a^x=M(a)a^x $$ where the mystery number $M(a)$ is the slope of the tangent line at zero: $$ M(a)=\\left.\\frac d {dx}a^x\\right\\vert_{x=0}=\\lim_{\\Delta x\\to 0}\\frac{a^{\\Delta x}-1}{\\Delta x} $$\nDefinition of $e$ The base $e$ is the unique real number so that $$ \\frac d{dx}e^x=e^x $$\nDifferentiating Exponential Function with other Bases We can finally identify out mystery number, and differentiate exponential functions with any base.\nFor any postivie constant $a$, $$ \\frac d{dx}a^x=a^x\\ln a $$\nProperties of $x$ $\\log_a(x)$ is the inverse function of $ a^x$.\nThe natural log, denoted $\\ln(x)$, is the inverse function of $e^x$.\nWe have\n$\\ln e^x=x$ $e^{\\ln x}=x$ $\\ln(ab)=\\ln(a)+\\ln(b)$ $\\ln(a^b)=b\\cdot\\ln(a)$ The Derivative of the Natural Logarithm\nNow we can differentiate more basic function: $$ \\frac d {dx}\\ln x=\\frac 1 x $$\n","date":"2025-03-04T00:00:00Z","permalink":"https://jiansyuan.github.io/post/mit_18.01/mit_18.01.1_calculus_ia-unit2/","section":"post","tags":["Note","Mathematics","Calculus"],"title":"Notes on MIT 18.01.1 Calculus IA (Unit2 Differentiation)"},{"categories":["MIT 18.x"],"contents":"Preface This is the note of the MIT Course 18.01.1 Calculus. For more details, refer to MIT 18.x Catalog, and it can also be found at MIT Open Learning Library.\nUnit 1: The Derivative The Definition of Average Rate of Change The average rate of change of a function $f(x)$ over an interval $a\\le x\\le b$ is defined to be $$ \\frac {f(b)-f(a)}{b-a} $$\nGeometrically In geometrical, the average rate of change is the slope of the secant line through the points $(a,f(a))$ and $(b,f(b))$.\nThe Definition of the Derivative The derivative of a function $f(x)$ at a point $x=a$ is defined as $$ f^\\prime(a)=\\lim_{b\\to a}\\frac{f(b)-f(a)}{b-a} $$\nGeometrically In geometrical, the derivative $f^\\prime(a)$ is the slope of the tangent line to the function $f$ through the point $(a, f(a))$.\nProperty of Derivatives The derivative of a function is itself a function, and satsifies the following linearity properties:\nDerivatives of Constant Multiples If $g(x)=k\\cdot f(x)$ for some constant $k$, then $$ g^\\prime(x)=k\\cdot f^\\prime(x) $$ at all points where $f$ is differentiable.\nDerivatives of Sums If $h(x)=f(x)+g(x)$, then $$ h^\\prime(x)=g^\\prime(x)+f^\\prime(x) $$ at all points where $f$ and $g$ are differentiable.\nDerivatives of Differences If $h(x)=f(x)-g(x)$, then $$ h^\\prime(x)=f^\\prime(x)-g^\\prime(x) $$ at all points where $f$ and $g$ are differentiable.\nThe Power Rule If $n$ is any fixed real numberm, and $f(x)=x^n$, then $f^\\prime(x)=n\\cdot x^{n-1}$.\nProperties of Leibniz Notation Unit: Suppose $P$ has units of pressure and $t$ has units of time. Then the derivative $$ \\frac{dP}{dt} $$ has units of pressure per unit time.\nEvaluating at Points: To denote the derivative of a function at a particular point, for example at $x=3$, we write $$ \\left.\\frac{df}{dx}\\right|_{x=3}, $$ where the ertical bar indicates that the derivative is evaluated at $x=3$.\nDerivatives Acting on Functions:\nOne may write $$ \\frac{d}{dx}\\left(x^2\\right) $$ for the derivative of $x^2$.\nAlternatively, we may write $$ \\frac{d}{dy}\\left(y^3+2y^2\\right). $$ for a more complex function $y^3+2y^2$.\nSecond Derivative The second derivative of a function $f(x)$ is defined as the derivative of $f^\\prime(x)$, and is denoted by either $$ f^{\\prime\\prime}(x) $$ or $$ \\frac{d^2 f}{dx^2} $$ Notice that in the Leibniz Notation for the second derivative, the square in the demoniator should be marked on the $d$, while in the numerator, the squre should be placed after $x$.\nSecond Derivative and Concavity Summary On intervals where $f^{\\prime\\prime}\u0026gt;0$, the function $f$ is concave up.\nOn intervals where $^{\\prime\\prime}\u0026lt;0$, the function $f$ is concave down.\nDerivative of Sine and Cosine $$ \\begin{aligned} \\frac d {dx} sin(x)\\quad\u0026amp;=\\quad cos(x)\\\\ \\frac d {dx} cos(x)\\quad\u0026amp;=\\quad-sin(x)\\\\ \\frac {d^2} {dx^2} sin(x)\\quad\u0026amp;=\\quad -sin(x)\\\\ \\frac {d^2} {dx^2} cos(x)\\quad\u0026amp;=\\quad -cos(x) \\end{aligned} $$\n","date":"2025-03-03T00:00:00Z","permalink":"https://jiansyuan.github.io/post/mit_18.01/mit_18.01.1_calculus_ia-unit1/","section":"post","tags":["Note","Mathematics","Calculus"],"title":"Notes on MIT 18.01.1 Calculus IA (Unit1 Derivative)"},{"categories":["MIT 18.x"],"contents":"Preface This is the note of the MIT Course 18.01.1 Calculus. For more details, refer to MIT 18.x Catalog, and it can also be found at MIT Open Learning Library.\nUnit 0: Limits Definition of One-Sided Limit Suppose $f(x)$ gets really close to $R$ for values of $x$ that get really close to and are not equal to $a$ from the right. Then we say $R$ is the right-hand limit of the function $f(x)$ as $x$ approaches $a$ from the right.\nWe note $$ f(x)\\to R\\ as\\ x\\to a^+\\\\ or\\\\ \\lim_{x\\to a^+}f(x)=R $$ If $f(x)$ gets really close to $L$ for values of $x$ that get really close to and are not equal to $a$ from the left, we say that $L$ is the left-hand limit of the function $f(x)$ as $x$ approaches $a$ from the left.\nWe note $$ f(x)\\to L\\ as\\ x\\to a^-\\\\ or\\\\ \\lim_{x\\to a^-}f(x)=L $$\nDefinition of the Limit If a function $f(x)$ approaches some value $L$ as $x$ approaches $a$ from both the right and the left, then the limit of $f(x)$ exists and equals $L$.\nWrite the limit in symbols, if $$ \\lim_{x\\to a^+}f(x)=\\lim_{x\\to a^-}f(x)=L $$ then $$ \\lim_{x\\to a}f(x) = L $$ In other way, $$ f(x)\\to L \\quad as\\quad x\\to a $$ The important thing is that $x$ is approaching $a$ but does not equal $a$.\nHere is the formal definition of the limit:\nThe statement $\\lim_{x\\to a}f(x)=L$ is defined as:\nFor all $\\varepsilon\u0026gt;0$, there exists some $\\delta\u0026gt;0$ such that if $0\u0026lt;|x-a|\u0026lt;\\delta$, then $|f(x)-L|\u0026lt;\\varepsilon$.\nThe Limit Laws Suppose $\\lim_{x\\to a}f(x)=L,\\quad \\lim_{x\\to a}g(x)=M$.\nThen here are some Limit Laws: $$ \\begin{aligned} \\text{Addition:}\\quad \u0026amp;\\lim_{x\\to a}[f(x)+g(x)]\u0026amp;=\u0026amp;\\quad L+M\\\\ \\text{Subtraction:}\\quad \u0026amp;\\lim_{x\\to a}[f(x)-g(x)]\u0026amp;=\u0026amp;\\quad L-M\\\\ \\text{Multiplication:}\\quad \u0026amp;\\lim_{x\\to a}[f(x)\\cdot g(x)]\u0026amp;=\u0026amp;\\quad L\\cdot M \\end{aligned} $$ It is noteworthy that we only have part of the Limit Law for Divison:\nIf $\\lim_{x\\to a}f(x)=L$ and $\\lim_{x\\to a}g(x)=M$, then:\nIf $M\\ne 0$, then $\\lim_{x\\to a}\\frac {f(x)}{g(x)}=\\frac L M$ If $M=0$, then $\\lim_{x\\to a}\\frac{f(x)}{g(x)}$ does not exist If $M=0$ and $L= 0$, then $\\lim_{x\\to a}\\frac{f(x)}{g(x)}$ might exist or not exist. It is necessary to do more work to determine whether or not its limit exists, and what it is if it does exist. Definition of Continuous at a Point We say that a function $f$ is continuous at a point $x=a$ if $$ \\lim_{x\\to a}f(x)=f(a) $$ In particular, if either $f(a)$ or $\\lim_{x\\to a}f(x)$ fails to exist, then $f$ is discontinuous at $a$.\nWe say that a function $f$ is right-continuous at a point $x=a$ if $\\lim_{x\\to a^+}f(x)=f(a)$.\nWe say that a function $f$ is left-continuous at a point $x=a$ if $\\lim_{x\\to a^-}f(x)=f(a)$.\nWe say that a function $f$ has a jump discontinuity at $x=a$ if both of the left-hand limit $\\lim_{x\\to a^-}f(x)$ and the right-hand limit $\\lim_{x\\to a^+}f(x)$ exist but they are not equal.\nWe say that a function $f$ has a removable discontinuity at $x=a$ if the overall limit $\\lim_{x\\to a}f(x)$ exists, but the $\\lim_{x\\to a}f(x)\\ne f(a)$.\nBasic Continuous Functions The following functions are continuous at all real numbers:\nall polynomials $\\sqrt[3]{x}$ $|x|$ $\\cos(x)$ and $\\sin(x)$ exponential functions $a^x$ which has $a\u0026gt;0$. The following functions are continuous at the specified values of $x$:\n$\\sqrt{x}, \\forall x\u0026gt;0$ $\\tan(x), \\forall x\\ \\text{is defined}$ logarithmic functions $\\log_a x$, where $a\\in(0,\\infty)$ with $a\\neq 1$ and $x\\in(0,\\infty)$. Intermediate Value Theorem If the function $f$ is continuous on the interval $[a,b]$, and $M$ lies between the values of $f(a)$ and $f(b)$, then there is at least one point $c$ between $a$ and $b$ such that $f(c)=M$.\nIn other words, a function $f$ is continuous on a closed interval $[a,b]$ if it is right-continuous at $a$, left-continuous at $b$, and continuous at all points between $a$ and $b$.\n","date":"2025-03-02T00:00:00Z","permalink":"https://jiansyuan.github.io/post/mit_18.01/mit_18.01.1_calculus_ia-unit0/","section":"post","tags":["Note","Mathematics","Calculus"],"title":"Notes on MIT 18.01.1 Calculus IA (Unit0 Limit)"},{"categories":["Algorithms"],"contents":"先决知识 基本的图论和数据结构知识 线段树(Segment Tree) DFS序(Depth-first-search SEQ.) 基本思想 树链剖分(Tree Chain Partition)的思路是将一整颗树剖分若干条链, 组合这些链成为线性结构从而能使用其他数据结构维护信息.具体地, 按照判链条件来讲有多种剖分方式, 如重链剖分, 长链剖分以及实链剖分. 本文要介绍被广泛运用的重链剖分.\n重链剖分以子树的大小为依据来确定该子树的根节点是否在链上, 链的数量不超过 $\\log_2N$ 条. 链在树的结构上是延续的, 一条链中的每一个节点所映射到的线性结构上的标号也是延续的. 这样能实现 $\\Omicron(\\log_2N)$ 级别的任意两点之间的查询树上路径和, 树上路径极值等, 以及对树上单点或区间值的修改操作.\n给出定义 重子节点(重儿子): 对于一个节点的所有子节点中, 所有子树的节点最多的那一个子节点. 轻子节点(轻儿子): 对于一个节点的所有子节点中, 所有不是重子节点的其他子节点. 重边: 一条边中如果深度更深的节点是重子节点, 那这条边就叫重边. 轻边: 所有不是重边的边. 重链: 由一或多条重边连接成的延续的路径. 轻链: 所有不是重链的链. 如图, 在这一颗树中, 被以红色填充的点是重子节点, 额外被两条红线标记的边是重边. 该图符合上文给出的定义, 可以看出图上存在三条重链.\n过程分析 我们首先通过两次的 $DFS$ 来计算出一些信息.\nDFS_1 给出以下伪代码:\n这段代码处理了每个节点的 $father, heavy_son, depth, size$ 这些信息, 其中 $size$ 是以这个点为根的子树的点数量.\nDFS_2 这段代码处理出每个点映射到线性结构上对应的标号 $index$ 和线性结构每个标号对应到的点 $new_id$. 还按照定义处理出重子节点 $heavy_son$, 以及重链链头信息 $top$.\n线段树 随后就能根据 $new_id$ 建出一颗线段树, 提供对区间求和的更新和查询操作. 这是一个很自然的过程, 不多赘述.\n路径查询/修改 和常规的倍增 $LCA$ 操作思想类似, 如下:\n如果两点在同一重链上 (链头相同), 答案加上两点 $index$ 在线段树上的区间和, 结束。 否则, 对于深度更深的点, 答案加上链头和当前 $index$ 在线段树上区间和, 跳到所在链头上, 一直如此直到在同一条重链上执行才执行上面的操作. 这里是因为链上连续节点在线性结构上连续的性质. 类似地, 路径修改就是把上面的线段树操作换成区间修改.\n子树查询/修改 从前面的$DFS_2$ 可以发现, 重链抛分同样具有 $DFS$ 序的子树连续性质. 所以说只要作一次线段树上的区间查询或者修改操作就行了.\n参考实现 LGP3384 模板题 #include \u0026lt;bits/stdc++.h\u0026gt; using namespace std; const int N = 1e6+5; int n, m, r, p, cnt=0, num[N], hes[N], siz[N], fat[N], dep[N], top[N], idx[N], nid[N]; vector\u0026lt;int\u0026gt; g[N]; int dfs1(int rt, int fa, int deep){ fat[rt]=fa, siz[rt]=1, dep[rt]=deep; for(auto i : g[rt]){ if(i==fa) continue; siz[rt]+=dfs1(i, rt, deep+1), hes[rt]=siz[hes[rt]]\u0026gt;siz[i]?hes[rt]:i; } return siz[rt]; } void dfs2(int rt, int tp){ idx[rt]=++cnt, nid[cnt]=num[rt], top[rt]=tp; if(hes[rt]) dfs2(hes[rt], tp); for(auto i : g[rt]) if(i!=fat[rt] \u0026amp;\u0026amp; i!=hes[rt]) dfs2(i, i); } //Start Segment Tree here... struct Tree{ int sum, laz, len; }tre[N]; #define l(a) (a\u0026lt;\u0026lt;1) #define r(a) (a\u0026lt;\u0026lt;1|1) #define push_up(a) tre[rt].sum = tre[l(rt)].sum+tre[r(rt)].sum void build_tree(int l, int r, int rt){ tre[rt].len = r-l+1; if(l==r) { tre[rt].sum=nid[l]; return ;} int mid = (l+r)\u0026gt;\u0026gt;1; build_tree(l, mid, l(rt)), build_tree(mid+1, r, r(rt)), push_up(rt); } inline void push_down(int rt){ if(!tre[rt].laz) return; tre[l(rt)].laz+=tre[rt].laz, tre[l(rt)].laz%=p; tre[r(rt)].laz+=tre[rt].laz, tre[r(rt)].laz%=p; tre[l(rt)].sum+=tre[rt].laz*tre[l(rt)].len, tre[l(rt)].sum%=p; tre[r(rt)].sum+=tre[rt].laz*tre[r(rt)].len, tre[r(rt)].sum%=p, tre[rt].laz=0; } void update_tree(int stdl, int stdr, int l, int r, int rt, int val){ if(stdl\u0026lt;=l\u0026amp;\u0026amp;r\u0026lt;=stdr){ tre[rt].sum += tre[rt].len*val%p, tre[rt].sum%=p, tre[rt].laz+=val; return; } push_down(rt); int mid = (l+r)\u0026gt;\u0026gt;1; if(stdl\u0026lt;=mid) update_tree(stdl, stdr, l, mid, l(rt), val); if(mid+1\u0026lt;=stdr) update_tree(stdl, stdr, mid+1, r, r(rt), val); push_up(rt); } int query_tree(int stdl, int stdr, int l, int r, int rt){ if(stdl\u0026lt;=l\u0026amp;\u0026amp;r\u0026lt;=stdr) return tre[rt].sum; push_down(rt); int mid = (l+r)\u0026gt;\u0026gt;1, ret=0; if(stdl\u0026lt;=mid) ret+=query_tree(stdl, stdr, l, mid, l(rt)); if(mid+1\u0026lt;=stdr) ret+=query_tree(stdl, stdr, mid+1, r, r(rt)); return (ret+p)%p; } void update_chain(int x, int y, int val){ int tmpx = top[x], tmpy = top[y]; while(tmpx != tmpy){ if(dep[tmpx]\u0026lt;dep[tmpy]) swap(x, y), swap(tmpx, tmpy); update_tree(idx[tmpx], idx[x], 1, cnt, 1, val); x = fat[tmpx], tmpx = top[x]; } if(idx[x] \u0026gt; idx[y]) swap(x, y); update_tree(idx[x], idx[y], 1 ,cnt, 1, val); } int query_chain(int x, int y){ int ret=0, tmpx=top[x], tmpy=top[y]; while(tmpx != tmpy){ if(dep[tmpx]\u0026lt;dep[tmpy]) swap(x, y), swap(tmpx, tmpy); ret += query_tree(idx[tmpx], idx[x], 1, cnt, 1); x = fat[tmpx], tmpx = top[x]; } if(idx[x]\u0026gt;idx[y]) swap(x, y); return (ret + query_tree(idx[x], idx[y], 1, cnt, 1) + p)%p; } int main(){ cin\u0026gt;\u0026gt;n\u0026gt;\u0026gt;m\u0026gt;\u0026gt;r\u0026gt;\u0026gt;p; for(int i=1;i\u0026lt;=n;i++) cin\u0026gt;\u0026gt;num[i], num[i]%=p; for(int i=1, x, y;i\u0026lt;n;i++) cin\u0026gt;\u0026gt;x\u0026gt;\u0026gt;y, g[x].push_back(y), g[y].push_back(x); dfs1(r, -114514, 0), dfs2(r, r), build_tree(1, n, 1); while(m--){ int opt, x, y, z; cin\u0026gt;\u0026gt;opt; if(opt==1) cin\u0026gt;\u0026gt;x\u0026gt;\u0026gt;y\u0026gt;\u0026gt;z, update_chain(x, y, z); else if(opt==2) cin\u0026gt;\u0026gt;x\u0026gt;\u0026gt;y, cout\u0026lt;\u0026lt;query_chain(x, y)\u0026lt;\u0026lt;\u0026#39;\\n\u0026#39;; else if(opt==3) cin\u0026gt;\u0026gt;x\u0026gt;\u0026gt;y, update_tree(idx[x], idx[x]+siz[x]-1, 1, n, 1, y); else if(opt==4) cin\u0026gt;\u0026gt;x, cout\u0026lt;\u0026lt;query_tree(idx[x], idx[x]+siz[x]-1, 1, n, 1)\u0026lt;\u0026lt;\u0026#39;\\n\u0026#39;; } } LGP3178/HAOI2015 \u0026ldquo;树上操作\u0026rdquo; #include \u0026lt;bits/stdc++.h\u0026gt; using namespace std; #define int long long const int N = 1e6+5; int n, m, cnt=0, num[N], hes[N], siz[N], fat[N], dep[N], top[N], idx[N], nid[N]; vector\u0026lt;int\u0026gt; g[N]; int dfs1(int rt, int fa, int deep){ fat[rt]=fa, siz[rt]=1, dep[rt]=deep; for(auto i : g[rt]){ if(i==fa) continue; siz[rt]+=dfs1(i, rt, deep+1), hes[rt]=siz[hes[rt]]\u0026gt;siz[i]?hes[rt]:i; } return siz[rt]; } void dfs2(int rt, int tp){ idx[rt]=++cnt, nid[cnt]=num[rt], top[rt]=tp; if(hes[rt]) dfs2(hes[rt], tp); for(auto i : g[rt]) if(i!=fat[rt] \u0026amp;\u0026amp; i!=hes[rt]) dfs2(i, i); } //Start Segment Tree here... struct Tree{ int sum, laz, len; }tre[N]; #define l(a) (a\u0026lt;\u0026lt;1) #define r(a) (a\u0026lt;\u0026lt;1|1) #define push_up(a) tre[rt].sum = tre[l(rt)].sum+tre[r(rt)].sum void build_tree(int l, int r, int rt){ tre[rt].len = r-l+1; if(l==r) { tre[rt].sum=nid[l]; return ;} int mid = (l+r)\u0026gt;\u0026gt;1; build_tree(l, mid, l(rt)), build_tree(mid+1, r, r(rt)), push_up(rt); } inline void push_down(int rt){ if(!tre[rt].laz) return; tre[l(rt)].laz+=tre[rt].laz; tre[r(rt)].laz+=tre[rt].laz; tre[l(rt)].sum+=tre[rt].laz*tre[l(rt)].len; tre[r(rt)].sum+=tre[rt].laz*tre[r(rt)].len, tre[rt].laz=0; } void update_tree(int stdl, int stdr, int l, int r, int rt, int val){ if(stdl\u0026lt;=l\u0026amp;\u0026amp;r\u0026lt;=stdr){ tre[rt].sum += tre[rt].len*val, tre[rt].laz+=val; return; } push_down(rt); int mid = (l+r)\u0026gt;\u0026gt;1; if(stdl\u0026lt;=mid) update_tree(stdl, stdr, l, mid, l(rt), val); if(mid+1\u0026lt;=stdr) update_tree(stdl, stdr, mid+1, r, r(rt), val); push_up(rt); } int query_tree(int stdl, int stdr, int l, int r, int rt){ if(stdl\u0026lt;=l\u0026amp;\u0026amp;r\u0026lt;=stdr) return tre[rt].sum; push_down(rt); int mid = (l+r)\u0026gt;\u0026gt;1, ret=0; if(stdl\u0026lt;=mid) ret+=query_tree(stdl, stdr, l, mid, l(rt)); if(mid+1\u0026lt;=stdr) ret+=query_tree(stdl, stdr, mid+1, r, r(rt)); return (ret); } void update_chain(int x, int y, int val){ int tmpx = top[x], tmpy = top[y]; while(tmpx != tmpy){ if(dep[tmpx]\u0026lt;dep[tmpy]) swap(x, y), swap(tmpx, tmpy); update_tree(idx[tmpx], idx[x], 1, cnt, 1, val); x = fat[tmpx], tmpx = top[x]; } if(idx[x] \u0026gt; idx[y]) swap(x, y); update_tree(idx[x], idx[y], 1 ,cnt, 1, val); } int query_chain(int x, int y){ int ret=0, tmpx=top[x], tmpy=top[y]; while(tmpx != tmpy){ if(dep[tmpx]\u0026lt;dep[tmpy]) swap(x, y), swap(tmpx, tmpy); ret += query_tree(idx[tmpx], idx[x], 1, cnt, 1); x = fat[tmpx], tmpx = top[x]; } if(idx[x]\u0026gt;idx[y]) swap(x, y); return ret + query_tree(idx[x], idx[y], 1, cnt, 1); } signed main(){ cin\u0026gt;\u0026gt;n\u0026gt;\u0026gt;m; for(int i=1;i\u0026lt;=n;i++) cin\u0026gt;\u0026gt;num[i]; for(int i=1, x, y;i\u0026lt;n;i++) cin\u0026gt;\u0026gt;x\u0026gt;\u0026gt;y, g[x].push_back(y), g[y].push_back(x); dfs1(1, -114514, 0), dfs2(1, 1), build_tree(1, n, 1); while(m--){ int opt, x, y, z; cin\u0026gt;\u0026gt;opt; if(opt==1) cin\u0026gt;\u0026gt;x\u0026gt;\u0026gt;y, update_tree(idx[x], idx[x], 1, n, 1, y); else if(opt==2) cin\u0026gt;\u0026gt;x\u0026gt;\u0026gt;y, update_tree(idx[x], idx[x]+siz[x]-1, 1, n, 1, y); else cin\u0026gt;\u0026gt;x, cout\u0026lt;\u0026lt;query_chain(1, x)\u0026lt;\u0026lt;\u0026#39;\\n\u0026#39;; } } ","date":"2023-03-26T00:00:00Z","permalink":"https://jiansyuan.github.io/post/talk-about-tree-chain-partition/","section":"post","tags":["Tutorial","Graph Theory"],"title":"Talk about Tree Chain Partition"},{"categories":["Algorithms"],"contents":"题意 今天不想简化题面。。。\nP 教授要去看奥运，但是他舍不得他的玩具，于是他决定把所有的玩具运到北京。\n他使用自己的压缩器进行压缩。这个压缩器可以将任意物品变成一维，再放到一种特殊的一维容器中。P 教授有编号为 $1\\dots n$ 的 $n$ 件玩具，玩具经过压缩后会变成一维，第 $i$ 件件玩具压缩后长度为 $C_i$。\n为了方便整理，P 教授要求：\n在一个一维容器中，玩具的编号是连续的； 如果一个一维容器中有多个玩具，那么两件玩具之间要加入一个单位长度的填充物。形式地说，如果要将 $i$ 号玩具到 $j$ 号玩具放到同一个容器中，则容器长度不小于 $x=j-i+\\sum_{k=i}^{j}C_k$。 制作容器的费用与容器的长度有关，根据教授研究，如果容器长度为 $x$，其制作费用为 $(x-L)^2$，其中 $L$ 是一个常量。\nP 教授不关心容器的数目，他可以制作出任意长度的容器，甚至超过 $L$。试求最小费用。\n数据范围：$1\\le n\\le 5\\times 10^4$，$1\\le L,C_i\\le 10^7$\n思路 DP : 斜率优化+单调队列\n朴素的解法 令$ans[i]$为选到第$i$个玩具时的最小费用, 列出朴素的状态转移方程: $$ ans[i]=\\min_{0\\le j\u0026lt;i}{(ans[j]+(i-j-1-L+\\Sigma_{k=j+1}^iC_k)^2)} $$ 如果$sum[i]=\\sum_{j=0}^iC_j$ : $$ ans[i]=\\min_{0\\le j\u0026lt;i}{(ans[j]+(i-j-1-L+sum[i]-sum[j])^2)} $$ 然后复杂度是$\\Omicron(n^2)$, 呜呜呜到底要怎么办呢.\n先把式子化简, 令$f[i]=sum[i]+i$ 和 $L\u0026rsquo;=L+1$, 就有了: $$ ans[i]=\\min_{0\\le j\u0026lt;i}{(ans[j]+(f[i]-f[j]-L^{\\prime})^2)} $$\n斜率方程 把和$j$无关的项移到左侧:\n$$ ans[i]-(f[i]-L\u0026rsquo;)^2=\\min_{0\\le j\u0026lt;i}{\\lbrace ans[j]+f[j]^2+2f[j] (L\u0026rsquo;-f[i])\\rbrace} $$\n把一次函数的斜截式$y=kx+b$移动得到$y-kx=b$. 发现可以这样表示: $$ \\begin{aligned} x_j=\u0026amp;f[j]\\\\ y_j=\u0026amp;ans[j]+f[j]^2\\\\ k_i=\u0026amp;-2(L\u0026rsquo;-f[i])\\\\ b_i=\u0026amp;ans[i]-(f[i]-L\u0026rsquo;)^2\\\\ \\end{aligned} $$ 所以转移方程也就是: $$ b_i=\\min_{0\\le j\u0026lt;i}{(y_j-k_ix_j)} $$ 其实就是求直线最小的截率$b_i$. 显然地, 答案在点集${(x_i, y_i)}$的下凸壳上, 具有决策单调性, 请自行证明.\n代码 const int N = 5e4+5; ll n, L, f[N], ans[N], qu[N], hd, tl; #define pow2(a) pow(a, 2) inline double slope(ll x, ll y){ return (double)((ans[y]+pow2(f[y]+L))-(ans[x]+pow2(f[x]+L)))/(2.0*(f[y]-f[x])); } int main(){ cin\u0026gt;\u0026gt;n\u0026gt;\u0026gt;L, L++; for(int i=1, tmp;i\u0026lt;=n;i++) cin\u0026gt;\u0026gt;tmp, f[i]=f[i-1]+tmp+1; for(int i=1;i\u0026lt;=n;i++){ while(hd\u0026lt;tl\u0026amp;\u0026amp;slope(qu[hd], qu[hd+1])\u0026lt;=f[i]) hd++; ans[i]=ans[qu[hd]]+pow2(f[i]-f[qu[hd]]-L); while(hd\u0026lt;tl\u0026amp;\u0026amp;slope(qu[tl], i)\u0026lt;slope(qu[tl-1], qu[tl])) tl--; qu[++tl]=i; } cout\u0026lt;\u0026lt;ans[n]\u0026lt;\u0026lt;endl; return 0; } ","date":"2023-03-22T00:00:00Z","permalink":"https://jiansyuan.github.io/post/solution-of-hnoi2008-pack-toys/","section":"post","tags":["Solution","HNOI","DP"],"title":"Solution of HNOI2008 “玩具装箱”(P3195)"},{"categories":["Algorithms"],"contents":"题意 有 $n$ 个相邻 距离为 $1$ 的地点编号为 $1-n$. 有 $m$ 个事件分别在地点 $a_i$ 时间 $t_i$ 发生, 在 $t_i$ 时位于地点 $x_{t_i}$ 能获得 $b_i-|a_i-x_{t_i}|$ 的收益, 要求 $|x_i-x_{i+1}|\\le d$. 求 $\\max{(\\sum{b_i-|a_i-x_{t_i}|})}$.\n其中 $1\\le n\\le 150000, 1\\le m\\le 300, 1\\le d\\le n$;\n$1\\le a_i\\le n, 1\\le b_i\\le 10^9, 1\\le t_i\\le 10^9$.\n思路 考虑 DP. 先令 $f[x][y]$ 为 $x_{t_x}=y$ 情况下的 $\\max{(\\sum_{i=1}^{x}{b_i-|a_i-x_{t_i}|})}$. 再用瞪眼法, 得出递推式子: $$ f[i][j]=\\max{(f[i-1][k]+b_i-|a_i-j|)} \\\\ :k\\in[x_{t_{i-1}}-d\\times(t_i-t_{i-1})),x_{t_{i-1}}+d\\times(t_i-t_{i-1}))]\\cap [1,n] $$\n时间复杂度是 $\\Omicron(n^2m)$. 考虑如何优化, 把 $b_i-|a_i-j|$ 提出. $$ f[i][j]=\\max{(f[i-1][k])}+b_i-|a_i-j| $$ 发现可以用单调栈均摊, 复杂度 $\\Omicron(nm)$.\n再考虑内存, 可以看出 $f[i][j]$ 的递推式只需要 $f[i-1][j]$, 把第一维优化掉.\n代码 #define ll long long const int N = 1.5e5+5, M = 305; ll a[M], b[M], t[M]; ll f[2][N]={0}; int main(){ int n, m, d; cin\u0026gt;\u0026gt;n\u0026gt;\u0026gt;m\u0026gt;\u0026gt;d; for(int i=1;i\u0026lt;=m;i++) cin\u0026gt;\u0026gt;a[i]\u0026gt;\u0026gt;b[i]\u0026gt;\u0026gt;t[i]; for(int i=1;i\u0026lt;=m;i++){ deque\u0026lt;int\u0026gt; q; ll h = (t[i]-t[i-1])*d; for(int j=1, k=1;j\u0026lt;=n;j++){ while(k\u0026lt;=j+h\u0026amp;\u0026amp;k\u0026lt;=n){ while(!q.empty()\u0026amp;\u0026amp;f[i\u0026amp;1][q.back()]\u0026lt;=f[i\u0026amp;1][k]) q.pop_back(); q.push_back(k), k++; } while(!q.empty()\u0026amp;\u0026amp;q.front()\u0026lt;(j-h)) q.pop_front(); f[!(i\u0026amp;1)][j]=f[i\u0026amp;1][q.front()]+b[i]-abs(a[i]-j); } } ll ans=-INT_MAX; for(int i=1;i\u0026lt;=n;i++) ans=max(ans, f[!(m\u0026amp;1)][i]); cout\u0026lt;\u0026lt;ans\u0026lt;\u0026lt;endl; return 0; } ","date":"2023-03-21T00:00:00Z","permalink":"https://jiansyuan.github.io/post/solution-of-cf372c/","section":"post","tags":["Solution","Codeforces","DP"],"title":"Solution of Codeforces372 C"},{"categories":["Algorithms"],"contents":"题意 有可重集$S$, 求它的非空子集$X$的个数, 满足: $X=A\\cup B, A\\cup B=\\emptyset, \\Sigma A_i=\\Sigma B_i$. 其中$|S| \\leq 20$, $S_i \\leq 10^8$.\n思路 考虑使用Meet in The Middle思路, 时间复杂度是朴素算法的平方根. 一般地, 把集合$S$分为两部分来搜索, 于是对于每个元素就有了三种分支: 不选, 选入左部分 和 选入右部分. 最后进行两部分的合并操作, 关键在于去重.\n代码 const int N = 30; int a[N]; bitset\u0026lt;1\u0026lt;\u0026lt;10\u0026gt; vis[1\u0026lt;\u0026lt;10]; unordered_map\u0026lt;int, bitset\u0026lt;1\u0026lt;\u0026lt;10\u0026gt; \u0026gt; mp; struct Node{ int dep, sum, sta; }; int main(){ int n, mid; cin\u0026gt;\u0026gt;n, mid = n\u0026gt;\u0026gt;1; for(int i=0;i\u0026lt;n;i++) cin\u0026gt;\u0026gt;a[i]; stable_sort(a, a+n); queue\u0026lt;Node\u0026gt; q; q.push(Node{0, 0, 0}); while(!q.empty()){ int x =q.front().dep, y=q.front().sum, z=q.front().sta; q.pop(); if(x==mid) { mp[y].set(z); continue; } q.push(Node{x+1, y, z}); q.push(Node{x+1, y+a[x], z|(1\u0026lt;\u0026lt;x)}); q.push(Node{x+1, y-a[x], z|(1\u0026lt;\u0026lt;x)}); } q.push(Node{mid, 0, 0}); int ans=0; while(!q.empty()){ int x =q.front().dep, y=q.front().sum, z=q.front().sta; q.pop(); if(x==n){ if(mp.count(y)) { bitset\u0026lt;1\u0026lt;\u0026lt;10\u0026gt; tmp(mp[y]); tmp \u0026amp;=~vis[z], ans+=tmp.count(), vis[z]|=tmp; } continue; } q.push(Node{x+1, y, z}); q.push(Node{x+1, y+a[x], z|(1\u0026lt;\u0026lt;(x-mid))}); q.push(Node{x+1, y-a[x], z|(1\u0026lt;\u0026lt;(x-mid))}); } cout\u0026lt;\u0026lt;ans-1\u0026lt;\u0026lt;endl; } ","date":"2023-03-19T00:00:00Z","permalink":"https://jiansyuan.github.io/post/solution-of-usaco12open-g/","section":"post","tags":["Solution","USACO"],"title":"Solution of USACO12OPEN G(P3067)"},{"categories":["Program Verification"],"contents":"\r⚠ WARN： During my reorganization of the website, I encountered this article and discovered that it appears to have been left unfinished several years ago.\rIntroduction If we say that programming is through writing code, the combination of simple functions \u0026amp; components to realize the complex assembly, then proof is the combination of some simple proof steps to make the complex proof. Theorem proving tools like Coq \u0026amp; Isabelle allow us to describe mathematical definitions \u0026amp; mathematical proofs in the form of codes.\nWe use Coq here: Coq-Release@github.com. The online version of Coq is also able to be used. Here is a link to the official Coq documentation for review \u0026amp; reference, in order for readers\u0026rsquo; better reading. This article only guarantees that readers can establish a preliminary understanding of formal theorem proving \u0026amp; program verification. If you\u0026rsquo;re looking for a book with a richer and more substantial introduction to get familiar with Coq, I recommend you read the \u0026ldquo;Software Foundations Vol.1: Logical Foundations\u0026rdquo; at least.\n1. Proof Equation Equation is one of the base of math, we started with a proof about group theory.\nModule Group. Class GroupOperator: Type := { tote_set: Type; zero: tote_set; add: tote_set -\u0026gt; tote_set -\u0026gt; tote_set; neg: tote_set -\u0026gt; tote_set; }. Notation \u0026#34;0\u0026#34; := (zero). Notation \u0026#34;a + b\u0026#34; := (add a b). Notation \u0026#34;- a\u0026#34; := (neg a). Check forall (G: GroupOperator) (x y: tote_set), x + y = y + x. First, we have to define which operations a group contains. We can write without these coq-reserve words such as Type or Class here. To define a group operation, you can define the set tote_set first, \u0026amp; then it should contain the unit element zero, the binary operation add \u0026amp; an inverse operation neg.\nThe key word Notation in coq helps describe the related properties by using refiner words.\nAt the lastest line, the order Check can be understood as asking computer to check if the expression is syntactically legal. The point is that it just does in syntax but not about the proof.\nClass GroupProperties (G: GroupOperator): Prop := { associate: forall (a b c: tote_set), (a + b) + c = a + (b + c); left_unit_clear: forall (a: tote_set), 0 + a = a; left_inverstion_clear: forall (a: tote_set), (- a) + a = 0; }. We list 3 laws of the group, clearing left unit, clearing inverstion \u0026amp; associative law. It \u0026rsquo;s useful to the next part.\n1.1 Proving Right Inverse Property Theorem right_inverstion_clear {G: GroupOperator} {GP: GroupProperties G}: (forall (a: tote_set), a + (- a) = 0). The things after Theorem here needed to proof by us, Try to do!\nRequire Import Setoid. Proof. intros a. rewrite \u0026lt;- (left_unit_clear (a + (- a))). rewrite \u0026lt;- (left_inverstion_clear (- a)) at 1. rewrite associate. rewrite \u0026lt;- (associate (- a)). rewrite left_inverstion_clear. rewrite left_unit_clear. rewrite left_inverstion_clear. reflexivity. Qed. Here is the classical proof in group theory, that\u0026rsquo;s derived from the two properties of left unit element \u0026amp; left inverse element, to right inverse element.\nWe use intros to get the theorem a + (- a) = 0 that awaits to be prooved at line 1. Then use the keyword rewrite to convert the existing properties of this equation, the arrow to the left is \u0026lt;- means to use properties to transform a certain item of the equation from left to right, the -\u0026gt; is opposite operation, followed by the parentheses after the property name Content is used to match corresponding items. If you want to operate only on the matching item at a certain position, you can use the keyword at; if you think that Coq will not cause ambiguity with a certain instruction, you can even ignore the content of the parentheses. Finally, the reflexivity. says that the equation is reflexive, \u0026amp; now the equation is exactly the same on both sides, so it\u0026rsquo;s all of the proof. The Qed. is the end of the Proof. above. We have done all the work of this stupid theorem.\nIf you have doubts about a part of this part of the code, please leave it to CoqIDE to run this proof, it will be intuitive to observe the equation change in the goal window on the right. Use the shortcut keys \u0026ldquo;Ctrl + $\\uparrow$\u0026rdquo; and \u0026ldquo;Ctrl + $\\downarrow$\u0026rdquo; to quickly switch the row up or down.\n1.2 Proving Right Unit Property Based on the fundamental properties \u0026amp; the results we have proved, it is easy to prove the right unit property corresponding to the left unit property. The right unit property can be expressed as the a + 0 = a.\nTheorem right_unit_clear {G: GroupOperator} {GP: GroupProperties G}: forall (a: tote_set), a + 0 = a. Proof. intros. rewrite \u0026lt;- (left_inverstion_clear (a)). rewrite \u0026lt;- associate, right_inverstion_clear, left_unit_clear. reflexivity. Qed. So it was proven that right unit property. It is possible to write multiple commands together in Coq as in the above code.\n1.3 Proving Double Negation Property Next prove the double negation signelimination property.\nTheorem double_negation {G: GroupOperator} {GP: GroupProperties G}: forall (a: tote_set), - - a = a. Proof. intros. rewrite \u0026lt;- (left_unit_clear (--a)). rewrite \u0026lt;- (right_inverstion_clear (a)). rewrite associate, right_inverstion_clear, right_unit_clear. reflexivity. Qed. 2. Inductive Type, Recursive Definitions and Inductive proof 这几天不写了，待续。。。。 $$ \\sum_{\\sum_{\\sum_{114514}^{1919810}}^{\\sum_{114514}^{1919810}}}^{\\sum_{\\sum_{114514}^{1919810}}^{\\sum_{114514}^{1919810}}} $$\n","date":"2023-03-06T00:00:00Z","permalink":"https://jiansyuan.github.io/post/theorem-proving-and-program-verification-by-coq/","section":"post","tags":["Tutorial","Coq"],"title":"Theorem Proving \u0026 Program Verification by Coq"},{"categories":[],"contents":"Hi! Welcome to my blog website About this website.\n","date":"2023-03-05T00:00:00Z","permalink":"https://jiansyuan.github.io/post/hi-guest/","section":"post","tags":[],"title":"Welcome, guest."},{"categories":null,"contents":"","date":"2019-05-28T00:00:00Z","permalink":"https://jiansyuan.github.io/archives/","section":"","tags":null,"title":""}]